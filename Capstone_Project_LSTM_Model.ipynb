{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "\n",
    "# specify to ignore warning messages\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the stock prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Apple</th>\n",
       "      <th>Netflix</th>\n",
       "      <th>Google</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-02-23</th>\n",
       "      <td>2.519421</td>\n",
       "      <td>1.625882</td>\n",
       "      <td>5.116364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-02-24</th>\n",
       "      <td>2.556677</td>\n",
       "      <td>1.639269</td>\n",
       "      <td>5.161938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-02-25</th>\n",
       "      <td>2.566709</td>\n",
       "      <td>1.631767</td>\n",
       "      <td>5.150848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-02-26</th>\n",
       "      <td>2.544857</td>\n",
       "      <td>1.631473</td>\n",
       "      <td>5.137707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-02-27</th>\n",
       "      <td>2.546206</td>\n",
       "      <td>1.644245</td>\n",
       "      <td>5.140106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Apple   Netflix    Google\n",
       "date                                    \n",
       "2009-02-23  2.519421  1.625882  5.116364\n",
       "2009-02-24  2.556677  1.639269  5.161938\n",
       "2009-02-25  2.566709  1.631767  5.150848\n",
       "2009-02-26  2.544857  1.631473  5.137707\n",
       "2009-02-27  2.546206  1.644245  5.140106"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_names = ['Apple','Netflix','Google']\n",
    "# Define empty dataframe to store the stock closing prices\n",
    "df = pd.DataFrame()\n",
    "for stock in stock_names:\n",
    "    # Read the stock closing prices with date as the index column.\n",
    "    df[stock] = pd.read_csv(stock+'.csv',parse_dates= [0], index_col = 'date',skiprows = [1]).close\n",
    "# Rearange the data in ascending chronological order\n",
    "df = df.sort_index()\n",
    "# Forward fill the missing holiday and weekend stock closing prices\n",
    "df = df.resample('D').ffill()\n",
    "# Log-transform the closing price data frame\n",
    "df_log = np.log(df)\n",
    "# Define a random seed for the test results\n",
    "np.random.seed(0)\n",
    "# Display first five five rows of the data frame\n",
    "df_log.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Absolute Percentage Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAPE(y_true,y_pred):\n",
    "    \"\"\"  input:\n",
    "    y_true = True value of variables\n",
    "    y_pred = predicted values of variable\n",
    "    output:\n",
    "    MAPE = mean absolute percentage error\n",
    "    \"\"\"\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred) # make sure input is flat   \n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long Short Term Memory Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_model(indata,test_size, WINDOW = 20, scale = 1):\n",
    "    \"\"\" input\n",
    "    indata: time series\n",
    "    test_size = prediction period length\n",
    "    WINDOW = number of past lags to consider, default value of last 20 days\n",
    "    scale = 1/0 if data to be scaled/or not\n",
    "    \"\"\"\n",
    "    # preprocess the data\n",
    "    data = indata.values\n",
    "    data = data.reshape(-1,1)\n",
    "    test = data[-test_size:]\n",
    "    ###########################################\n",
    "    #If scale = 1 normalize the data in 0,1 range\n",
    "    if scale:\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        data = scaler.fit_transform(data)\n",
    "    ###########################################\n",
    "    ## Convert the data into features and varaible form\n",
    "    ###########################################\n",
    "    # Train features and variables\n",
    "    trainX, trainY = [], []\n",
    "    for i in range(WINDOW,len(indata)-test_size):\n",
    "        trainX.append(data[i-WINDOW:i,0])\n",
    "        trainY.append(data[i,0])\n",
    "    trainX, trainY = np.array(trainX), np.array(trainY)\n",
    "    trainX = np.reshape(trainX, (trainX.shape[0],trainX.shape[1],1))\n",
    "    ###########################################\n",
    "    # Test features and varaibles\n",
    "    test_data = indata[len(indata) - test_size - WINDOW:].values\n",
    "    test_data = test_data.reshape(-1,1)\n",
    "    if scale:\n",
    "        test_data  = scaler.transform(test_data)\n",
    "    testX, testY = [],[]\n",
    "    for i in range(WINDOW,test.shape[0]):\n",
    "        testX.append(test_data[i-WINDOW:i,0])\n",
    "        testY.append(test_data[i,0])\n",
    "    testX, testY = np.array(testX), np.array(testY)\n",
    "    testX = np.reshape(testX, (testX.shape[0],testX.shape[1],1))\n",
    "    ###########################################\n",
    "    # LSTM model training\n",
    "    # Sequential model is trained\n",
    "    model = Sequential()\n",
    "    # Add first layer with 50 neurons\n",
    "    model.add(LSTM(units=50, return_sequences=True, input_shape=(trainX.shape[1],1)))\n",
    "    # Add second layer with 50 neurons\n",
    "    model.add(LSTM(units=50))\n",
    "    # Final single variable output\n",
    "    model.add(Dense(1))\n",
    "    ###########################################\n",
    "    # Compile the model with MSE and Adam optimizer\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    # Fit the model using training features and variables\n",
    "    model.fit(trainX, trainY, epochs=1, batch_size=1, verbose=2)\n",
    "    ###########################################\n",
    "    # Compute the yhat (predicted varaible values)\n",
    "    train_predict = model.predict(trainX)\n",
    "    test_predict = model.predict(testX)\n",
    "    ###########################################\n",
    "    # Return the data in not scaled form\n",
    "    if scale:\n",
    "        train_predict = scaler.inverse_transform(train_predict)\n",
    "        test_predict = scaler.inverse_transform(test_predict)\n",
    "\n",
    "    return train_predict,test_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Fit and Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/pardeepkumar/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/pardeepkumar/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/1\n",
      " - 87s - loss: 8.8086e-04\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values does not match length of index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b01e6e832b43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_log\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstock_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWINDOW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWINDOW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdf_lstm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstock_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mWINDOW\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mdf_lstm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstock_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_Predict'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3117\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3118\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3119\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3121\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3193\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3194\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3195\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, key, value, broadcast)\u001b[0m\n\u001b[1;32m   3389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3390\u001b[0m             \u001b[0;31m# turn me into an ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3391\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sanitize_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3392\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3393\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_sanitize_index\u001b[0;34m(data, index, copy)\u001b[0m\n\u001b[1;32m   3999\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4000\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4001\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Length of values does not match length of '\u001b[0m \u001b[0;34m'index'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4003\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCIndexClass\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values does not match length of index"
     ]
    }
   ],
   "source": [
    "WINDOW = 20\n",
    "len_test = len(df['2019-02-01':])\n",
    "df_lstm = pd.DataFrame()\n",
    "for i in range(3):\n",
    "    train,test = LSTM_model(df_log[stock_names[i]],test_size = len_test, WINDOW = WINDOW,scale = 1)\n",
    "    df_lstm[stock_names[i]] = df_log.iloc[WINDOW:,i]\n",
    "    df_lstm[stock_names[i]+'_Predict'] = np.concatenate((train,test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock plots after 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3,1, figsize=(15, 10), facecolor='w', edgecolor='k',sharex = True)\n",
    "for i in range(3):\n",
    "    df_lstm.loc['2018-01-01':,stock_names[i]].plot(ax = axs[i], color = 'blue')\n",
    "    df_lstm.loc['2018-01-01':'2019-02-01',stock_names[i]+'_Predict'].plot(ax = axs[i], color = 'green')\n",
    "    df_lstm.loc['2019-02-01':,stock_names[i]+'_Predict'].plot(ax = axs[i], color='red',marker = '*',markersize = '2')\n",
    "    \n",
    "    axs[2].set_xlabel('Date',size = '15')\n",
    "    axs[i].set_ylabel(r'$log(P_{close} ,\\$ $)', size = '15')\n",
    "    axs[i].legend(['Original','Fitted','Prediction'],loc = 'upper left')\n",
    "    axs[i].set_title(stock_names[i], size = '15')\n",
    "    axs[i].set_xlim(['2018-01-01','2019-02-23'])    \n",
    "    axs[0].set_ylim([4.9,5.5])\n",
    "    axs[1].set_ylim([5.3,6.1])\n",
    "    axs[2].set_ylim([6.8,7.3])   \n",
    "    axs[i].grid()\n",
    "plt.subplots_adjust(wspace = 0.04, hspace = 0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lstm.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock plots after 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3,1, figsize=(15, 10), facecolor='w', edgecolor='k',sharex = True)\n",
    "for i in range(3):\n",
    "    df_lstm.loc['2019-01-01':,stock_names[i]].plot(ax = axs[i], color = 'blue', marker = 'o')\n",
    "    df_lstm.loc['2019-01-01':'2019-02-01',stock_names[i]+'_Predict'].plot(ax = axs[i], color = 'green', marker = '*')\n",
    "    df_lstm.loc['2019-02-01':,stock_names[i]+'_Predict'].plot(ax = axs[i], color='red', marker = '*')\n",
    "    mape = MAPE(df_lstm.loc['2019-02-01':,stock_names[i]],df_lstm.loc['2019-02-01':,stock_names[i]+'_Predict'])\n",
    "    axs[i].set_title('{} : Mean Absolute Precentage Error = {}%'.format(stock_names[i],np.around(mape,2)))\n",
    "    axs[i].grid()\n",
    "    axs[2].set_xlabel('Date',size = '15')\n",
    "    axs[i].set_ylabel(r'$log(P_{close} ,\\$ $)', size = '15')\n",
    "    axs[i].legend(['Original','Fitted','Prediction'],loc = 'upper left')\n",
    "    axs[0].set_ylim([4.9,5.3])\n",
    "    axs[1].set_ylim([5.5,6.0])\n",
    "    axs[2].set_ylim([6.9,7.1])\n",
    "    axs[i].set_xlim(['2019-01-01','2019-02-23'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
